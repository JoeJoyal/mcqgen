{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.1.4-cp39-cp39-win_amd64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from pandas)\n",
      "  Downloading numpy-1.26.3-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.2 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.2 kB 327.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.2/61.2 kB 324.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.1.4-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "Downloading numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 1.7 MB/s eta 0:00:10\n",
      "   ---------------------------------------- 0.2/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/15.8 MB 1.9 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.4/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/15.8 MB 2.1 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.5/15.8 MB 1.8 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/15.8 MB 1.6 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.6/15.8 MB 1.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.7/15.8 MB 1.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.8/15.8 MB 1.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.9/15.8 MB 1.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.0/15.8 MB 1.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.1/15.8 MB 1.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.3/15.8 MB 1.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.4/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.5/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.6/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 2.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.0/15.8 MB 2.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.6/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.7/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.8/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.9/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.0/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.2/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.3/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.4/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.5/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.7/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.8/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.0/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.1/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.9/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.0/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.0/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.1/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.2/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.2/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.3/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.3/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.3/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.4/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.4/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.5/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.6/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.6/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.7/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.8/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.8/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.9/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.0/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.1/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.2/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.2/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.3/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.7/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.9/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.2/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.3/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.3/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.4/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.5/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.5/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.6/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.7/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.7/15.8 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.7/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.8/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.8/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.8/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.8/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.8/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.9/15.8 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 7.9/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.0/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.0/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.1/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.1/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.1/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.2/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.2/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.3/15.8 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.3/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.3/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.4/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.4/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.4/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.5/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.6/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.6/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.6/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 8.7/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.7/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.9/15.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 9.1/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.1/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 9.5/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.5/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.6/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.6/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.6/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.7/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.7/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.8/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.8/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 9.9/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 10.0/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 10.1/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 10.1/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 10.2/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.3/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.3/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.4/15.8 MB 1.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.5/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.6/15.8 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.7/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.8/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.9/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 11.0/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 11.1/15.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.4/15.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.7/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.9/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 12.0/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 12.1/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 12.2/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 12.2/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.3/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.4/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.5/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.6/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.7/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.8/15.8 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.9/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.0/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.0/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.1/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.1/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.2/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.2/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.4/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.4/15.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.7/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.8/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.3/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.4/15.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.5/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.6/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.8/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.0/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 1.4 MB/s eta 0:00:00\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Using cached tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.3 pandas-2.1.4 pytz-2023.3.post1 tzdata-2023.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.0.354-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.25-cp39-cp39-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.1-cp39-cp39-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.8 (from langchain)\n",
      "  Using cached langchain_community-0.0.8-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.5 (from langchain)\n",
      "  Using cached langchain_core-0.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain)\n",
      "  Using cached langsmith-0.0.77-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from langchain) (1.26.3)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp39-cp39-win_amd64.whl.metadata (32 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio<5,>=3 (from langchain-core<0.2,>=0.1.5->langchain)\n",
      "  Using cached anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from langchain-core<0.2,>=0.1.5->langchain) (23.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.14.6-cp39-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain) (1.2.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached langchain-0.0.354-py3-none-any.whl (803 kB)\n",
      "Using cached aiohttp-3.9.1-cp39-cp39-win_amd64.whl (365 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_community-0.0.8-py3-none-any.whl (1.5 MB)\n",
      "Using cached langchain_core-0.1.5-py3-none-any.whl (205 kB)\n",
      "Using cached langsmith-0.0.77-py3-none-any.whl (48 kB)\n",
      "Using cached pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "Using cached pydantic_core-2.14.6-cp39-none-win_amd64.whl (1.9 MB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading SQLAlchemy-2.0.25-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB 393.8 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.1/2.1 MB 1.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.1 MB 1.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.1 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.5/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.7/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.0 MB/s eta 0:00:00\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Using cached frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp39-cp39-win_amd64.whl (290 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Using cached yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, mypy-extensions, multidict, marshmallow, jsonpointer, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic, jsonpatch, anyio, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community, langchain\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.25 aiohttp-3.9.1 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.2.0 async-timeout-4.0.3 attrs-23.2.0 certifi-2023.11.17 charset-normalizer-3.3.2 dataclasses-json-0.6.3 frozenlist-1.4.1 greenlet-3.0.3 idna-3.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.354 langchain-community-0.0.8 langchain-core-0.1.5 langsmith-0.0.77 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 pydantic-2.5.3 pydantic-core-2.14.6 requests-2.31.0 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0 urllib3-2.1.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from openai) (1.3.0)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\joejoyal\\anaconda3\\envs\\mcqgen\\lib\\site-packages (from PyPDF2) (4.9.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-3.5-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000215A8B93820>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000215A8BB4A00>, temperature=0.5, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"text\", \"numbers\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain =LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], \n",
    "                                        input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"C:\\Users\\Joejoyal\\mcqgen\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Joejoyal\\\\mcqgen\\\\data.txt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The academic discipline of artificial intelligence was founded at a research workshop at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[17] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[18] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[19][20] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[21]\n",
      "\n",
      "Artificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn't fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing's groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research which led it to be a landmark event as it set the precedent for two decades of rapid advancements in the field.[22]\n",
      "\n",
      "Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[23]\n",
      "\n",
      "Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[24][25][26] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[27][28]\n",
      "\n",
      "The field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[29]\n",
      "\n",
      "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
      "\n",
      "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[30] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[31] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[32]\n",
      "\n",
      "In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\n",
      "\n",
      "In March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[33] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of â€˜general human intelligenceâ€™\" as of 2023.\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"Generative AI\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:The academic discipline of artificial intelligence was founded at a research workshop at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[17] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[18] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[19][20] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[21]\n",
      "\n",
      "Artificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn't fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing's groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research which led it to be a landmark event as it set the precedent for two decades of rapid advancements in the field.[22]\n",
      "\n",
      "Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[23]\n",
      "\n",
      "Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[24][25][26] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[27][28]\n",
      "\n",
      "The field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[29]\n",
      "\n",
      "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
      "\n",
      "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[30] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[31] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[32]\n",
      "\n",
      "In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\n",
      "\n",
      "In March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[33] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of â€˜general human intelligenceâ€™\" as of 2023.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for Generative AI students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:The academic discipline of artificial intelligence was founded at a research workshop at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[17] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[18] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[19][20] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[21]\n",
      "\n",
      "Artificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn't fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing's groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research which led it to be a landmark event as it set the precedent for two decades of rapid advancements in the field.[22]\n",
      "\n",
      "Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[23]\n",
      "\n",
      "Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[24][25][26] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[27][28]\n",
      "\n",
      "The field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[29]\n",
      "\n",
      "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
      "\n",
      "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[30] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[31] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[32]\n",
      "\n",
      "In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\n",
      "\n",
      "In March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[33] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of â€˜general human intelligenceâ€™\" as of 2023.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for Generative AI students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:2961\n",
      "Prompt Tokens:2224\n",
      "Completion Tokens:737\n",
      "Total Cost:0.00481\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The academic discipline of artificial intelligence was founded at a research workshop at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[17] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[18] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[19][20] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[21]\\n\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea wasn\\'t fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research which led it to be a landmark event as it set the precedent for two decades of rapid advancements in the field.[22]\\n\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[23]\\n\\nMarkov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[24][25][26] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[27][28]\\n\\nThe field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[29]\\n\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\n\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[30] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[31] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[32]\\n\\nIn 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\\n\\nIn March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[33] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of â€˜general human intelligenceâ€™\" as of 2023.',\n",
       " 'number': 5,\n",
       " 'subject': 'Generative AI',\n",
       " 'tone': 'simple',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n  \"1\": {\\n    \"mcq\": \"Who is credited with founding the academic discipline of artificial intelligence?\",\\n    \"options\": {\\n      \"a\": \"Alan Turing\",\\n      \"b\": \"Harold Cohen\",\\n      \"c\": \"Andrey Markov\",\\n      \"d\": \"Daedalus\"\\n    },\\n    \"correct\": \"a\"\\n  },\\n  \"2\": {\\n    \"mcq\": \"Which event in 1956 set the precedent for rapid advancements in the field of AI?\",\\n    \"options\": {\\n      \"a\": \"The release of GPT-4\",\\n      \"b\": \"The Dartmouth Summer Research Project\",\\n      \"c\": \"The development of deep learning\",\\n      \"d\": \"The emergence of generative models\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"3\": {\\n    \"mcq\": \"Who created the computer program AARON to generate paintings?\",\\n    \"options\": {\\n      \"a\": \"Alan Turing\",\\n      \"b\": \"Harold Cohen\",\\n      \"c\": \"Andrey Markov\",\\n      \"d\": \"Daedalus\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"4\": {\\n    \"mcq\": \"Which mathematical concept has long been used to model natural languages?\",\\n    \"options\": {\\n      \"a\": \"Markov chains\",\\n      \"b\": \"Generative adversarial networks\",\\n      \"c\": \"Neural networks\",\\n      \"d\": \"Variational autoencoders\"\\n    },\\n    \"correct\": \"a\"\\n  },\\n  \"5\": {\\n    \"mcq\": \"What was the first generative pre-trained transformer model called?\",\\n    \"options\": {\\n      \"a\": \"GPT-4\",\\n      \"b\": \"GPT-2\",\\n      \"c\": \"Midjourney\",\\n      \"d\": \"Stable Diffusion\"\\n    },\\n    \"correct\": \"b\"\\n  }\\n}',\n",
       " 'review': '{\"1\": {\"mcq\": \"Who is credited with founding the academic discipline of artificial intelligence?\", \"options\": {\"a\": \"Alan Turing\", \"b\": \"Harold Cohen\", \"c\": \"Andrey Markov\", \"d\": \"Daedalus\"}, \"correct\": \"a\"}, \\n\"2\": {\"mcq\": \"When was the Dartmouth Summer Research Project on AI held?\", \"options\": {\"a\": \"1950\", \"b\": \"1956\", \"c\": \"1970\", \"d\": \"2000\"}, \"correct\": \"b\"}, \\n\"3\": {\"mcq\": \"Which artist created generative AI works using the computer program AARON?\", \"options\": {\"a\": \"Alan Turing\", \"b\": \"Harold Cohen\", \"c\": \"Andrey Markov\", \"d\": \"Daedalus\"}, \"correct\": \"b\"}, \\n\"4\": {\"mcq\": \"What breakthrough in deep learning enabled the creation of generative models for complex data like images?\", \"options\": {\"a\": \"Variational autoencoder\", \"b\": \"Generative adversarial network\", \"c\": \"Transformer network\", \"d\": \"Long-Short Term Memory models\"}, \"correct\": \"b\"}, \\n\"5\": {\"mcq\": \"Which generative AI model was released in 2023 and claimed to be an early version of an artificial general intelligence system?\", \"options\": {\"a\": \"GPT-1\", \"b\": \"GPT-2\", \"c\": \"DALL-E\", \"d\": \"GPT-4\"}, \"correct\": \"d\"}}'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'Who is credited with founding the academic discipline of artificial intelligence?',\n",
       "  'Choices': 'a: Alan Turing | b: Harold Cohen | c: Andrey Markov | d: Daedalus',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'Which event in 1956 set the precedent for rapid advancements in the field of AI?',\n",
       "  'Choices': 'a: The release of GPT-4 | b: The Dartmouth Summer Research Project | c: The development of deep learning | d: The emergence of generative models',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Who created the computer program AARON to generate paintings?',\n",
       "  'Choices': 'a: Alan Turing | b: Harold Cohen | c: Andrey Markov | d: Daedalus',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which mathematical concept has long been used to model natural languages?',\n",
       "  'Choices': 'a: Markov chains | b: Generative adversarial networks | c: Neural networks | d: Variational autoencoders',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'What was the first generative pre-trained transformer model called?',\n",
       "  'Choices': 'a: GPT-4 | b: GPT-2 | c: Midjourney | d: Stable Diffusion',\n",
       "  'Correct': 'b'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is credited with founding the academic dis...</td>\n",
       "      <td>a: Alan Turing | b: Harold Cohen | c: Andrey M...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which event in 1956 set the precedent for rapi...</td>\n",
       "      <td>a: The release of GPT-4 | b: The Dartmouth Sum...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the computer program AARON to gene...</td>\n",
       "      <td>a: Alan Turing | b: Harold Cohen | c: Andrey M...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which mathematical concept has long been used ...</td>\n",
       "      <td>a: Markov chains | b: Generative adversarial n...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the first generative pre-trained tran...</td>\n",
       "      <td>a: GPT-4 | b: GPT-2 | c: Midjourney | d: Stabl...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MCQ  \\\n",
       "0  Who is credited with founding the academic dis...   \n",
       "1  Which event in 1956 set the precedent for rapi...   \n",
       "2  Who created the computer program AARON to gene...   \n",
       "3  Which mathematical concept has long been used ...   \n",
       "4  What was the first generative pre-trained tran...   \n",
       "\n",
       "                                             Choices Correct  \n",
       "0  a: Alan Turing | b: Harold Cohen | c: Andrey M...       a  \n",
       "1  a: The release of GPT-4 | b: The Dartmouth Sum...       b  \n",
       "2  a: Alan Turing | b: Harold Cohen | c: Andrey M...       b  \n",
       "3  a: Markov chains | b: Generative adversarial n...       a  \n",
       "4  a: GPT-4 | b: GPT-2 | c: Midjourney | d: Stabl...       b  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv('quiz-generative-ai.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01_05_2024_02_03_43'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m_%d_%Y_%H_%M_%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
